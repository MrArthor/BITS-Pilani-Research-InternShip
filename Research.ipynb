{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c16ee6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "from os import mkdir\n",
    "from os.path import join, isdir\n",
    "from numpy import linalg as LA\n",
    "from math import sqrt, inf\n",
    "from decimal import Decimal\n",
    "import time\n",
    "import gym\n",
    "import envs\n",
    "from gym import spaces, logger\n",
    "from scenario_objects import Point, Cell, User, Environment\n",
    "import plotting\n",
    "from my_utils import *\n",
    "import agent\n",
    "from Astar import *\n",
    "'''import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "'''# _________ Main training parameters:_________\n",
    "\n",
    "SHOW_EVERY = 30\n",
    "LEARNING_RATE = 1.0\n",
    "DISCOUNT = 0.95\n",
    "EPSILON = 1.0\n",
    "EPSILON_DECREMENT = 0.998\n",
    "EPSILON_MIN = 0.01\n",
    "EPSILON_MIN2 = 0.4\n",
    "\n",
    "max_value_for_Rmax = 100\n",
    "ITERATIONS_PER_EPISODE = 40\n",
    "\n",
    "# _____________________________________________\n",
    "\n",
    "\n",
    "# __________________ Main loadings: __________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81b42ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8, 4]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('UAVEnv-v0')\n",
    "MAX_UAV_HEIGHT = env.max_uav_height\n",
    "n_actions = env.nb_actions\n",
    "actions_indeces = range(n_actions)\n",
    "cs_cells = env.cs_cells\n",
    "cs_cells_coords_for_UAVs = [(cell._x_coord, cell._y_coord) for cell in cs_cells] if DIMENSION_2D==True else [(cell._x_coord, cell._y_coord, cell._z_coord) for cell in cs_cells]\n",
    "#cells_matrix = env.cells_matrix\n",
    "action_set_min = env.action_set_min\n",
    "if (UNLIMITED_BATTERY==False):\n",
    "    q_table_action_set = env.q_table_action_set\n",
    "    charging_set = env.charging_set\n",
    "    come_home_set = env.come_home_set\n",
    "\n",
    "reset_uavs = env.reset\n",
    "centroids = env.cluster_centroids\n",
    "# Scale centroids according to the selected resolution:\n",
    "env_centroids = [(centroid[0]/CELL_RESOLUTION_PER_COL, centroid[1]/CELL_RESOLUTION_PER_ROW) for centroid in centroids]\n",
    "print(action_set_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73bbfffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<agent.Agent at 0x1a9a92fbd30>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent=env.agents\n",
    "agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "070afebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb9b3c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "612d4755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7db9b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad968a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0811d49f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "length, width= env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac87cdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bab200e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model(height, width, actions):\n",
    "    model = tensorflow.keras.Sequential()    \n",
    "    model.add(Dense(240, activation='relu', input_shape=(2,height, width)))\n",
    "    model.add(Dense(240, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b08a3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(length, width, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaf5dbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 2, 10, 240)        2640      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2, 10, 240)        57840     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4800)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               2458112   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,651,719\n",
      "Trainable params: 2,651,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98551978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2916193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=7)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02b748f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100 steps ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_5_input to have 4 dimensions, but got array with shape (1, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Drive\\Google Drive\\Codes\\GitHub\\Research\\Research.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Drive/Google%20Drive/Codes/GitHub/Research/Research.ipynb#ch0000014?line=0'>1</a>\u001b[0m dqn \u001b[39m=\u001b[39m build_agent(model, actions)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Drive/Google%20Drive/Codes/GitHub/Research/Research.ipynb#ch0000014?line=1'>2</a>\u001b[0m dqn\u001b[39m.\u001b[39mcompile(Adam())\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Drive/Google%20Drive/Codes/GitHub/Research/Research.ipynb#ch0000014?line=2'>3</a>\u001b[0m dqn\u001b[39m.\u001b[39;49mfit(env, nb_steps\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, visualize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\rl\\core.py:168\u001b[0m, in \u001b[0;36mAgent.fit\u001b[1;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[0;32m    165\u001b[0m callbacks\u001b[39m.\u001b[39mon_step_begin(episode_step)\n\u001b[0;32m    166\u001b[0m \u001b[39m# This is were all of the work happens. We first perceive and compute the action\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m# (forward step) and then use the reward to improve (backward step).\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(observation)\n\u001b[0;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessor\u001b[39m.\u001b[39mprocess_action(action)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\rl\\agents\\dqn.py:224\u001b[0m, in \u001b[0;36mDQNAgent.forward\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, observation):\n\u001b[0;32m    222\u001b[0m     \u001b[39m# Select an action.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mget_recent_state(observation)\n\u001b[1;32m--> 224\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_q_values(state)\n\u001b[0;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m    226\u001b[0m         action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mselect_action(q_values\u001b[39m=\u001b[39mq_values)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\rl\\agents\\dqn.py:68\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_q_values\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_q_values\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m---> 68\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_batch_q_values([state])\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     69\u001b[0m     \u001b[39massert\u001b[39;00m q_values\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions,)\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\rl\\agents\\dqn.py:63\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_batch_q_values\u001b[1;34m(self, state_batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_batch_q_values\u001b[39m(\u001b[39mself\u001b[39m, state_batch):\n\u001b[0;32m     62\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_state_batch(state_batch)\n\u001b[1;32m---> 63\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict_on_batch(batch)\n\u001b[0;32m     64\u001b[0m     \u001b[39massert\u001b[39;00m q_values\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39mlen\u001b[39m(state_batch), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions)\n\u001b[0;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_v1.py:1304\u001b[0m, in \u001b[0;36mModel.predict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1299\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`predict_on_batch` is not supported for models distributed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1301\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith tf.distribute.Strategy.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1302\u001b[0m     )\n\u001b[0;32m   1303\u001b[0m \u001b[39m# Validate and standardize user data.\u001b[39;00m\n\u001b[1;32m-> 1304\u001b[0m inputs, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize_user_data(\n\u001b[0;32m   1305\u001b[0m     x, extract_tensors_from_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   1306\u001b[0m )\n\u001b[0;32m   1307\u001b[0m \u001b[39m# If `self._distribution_strategy` is True, then we are in a replica\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[39m# context at this point.\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_eagerly \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution_strategy:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_v1.py:2649\u001b[0m, in \u001b[0;36mModel._standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2640\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2641\u001b[0m     \u001b[39mnot\u001b[39;00m run_eagerly\n\u001b[0;32m   2642\u001b[0m     \u001b[39mand\u001b[39;00m is_build_called\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2645\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(_is_symbolic_tensor(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m all_inputs)\n\u001b[0;32m   2646\u001b[0m ):\n\u001b[0;32m   2647\u001b[0m     \u001b[39mreturn\u001b[39;00m [], [], \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2649\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize_tensors(\n\u001b[0;32m   2650\u001b[0m     x,\n\u001b[0;32m   2651\u001b[0m     y,\n\u001b[0;32m   2652\u001b[0m     sample_weight,\n\u001b[0;32m   2653\u001b[0m     run_eagerly\u001b[39m=\u001b[39;49mrun_eagerly,\n\u001b[0;32m   2654\u001b[0m     dict_inputs\u001b[39m=\u001b[39;49mdict_inputs,\n\u001b[0;32m   2655\u001b[0m     is_dataset\u001b[39m=\u001b[39;49mis_dataset,\n\u001b[0;32m   2656\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2657\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2658\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_v1.py:2690\u001b[0m, in \u001b[0;36mModel._standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2687\u001b[0m \u001b[39m# Standardize the inputs.\u001b[39;00m\n\u001b[0;32m   2688\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset)):\n\u001b[0;32m   2689\u001b[0m     \u001b[39m# TODO(fchollet): run static checks with dataset output shape(s).\u001b[39;00m\n\u001b[1;32m-> 2690\u001b[0m     x \u001b[39m=\u001b[39m training_utils_v1\u001b[39m.\u001b[39;49mstandardize_input_data(\n\u001b[0;32m   2691\u001b[0m         x,\n\u001b[0;32m   2692\u001b[0m         feed_input_names,\n\u001b[0;32m   2693\u001b[0m         feed_input_shapes,\n\u001b[0;32m   2694\u001b[0m         check_batch_axis\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# Don't enforce the batch size.\u001b[39;49;00m\n\u001b[0;32m   2695\u001b[0m         exception_prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   2696\u001b[0m     )\n\u001b[0;32m   2698\u001b[0m \u001b[39m# Get typespecs for the input data and sanitize it if necessary.\u001b[39;00m\n\u001b[0;32m   2699\u001b[0m \u001b[39m# TODO(momernick): This should be capable of doing full input validation\u001b[39;00m\n\u001b[0;32m   2700\u001b[0m \u001b[39m# at all times - validate that this is so and refactor the\u001b[39;00m\n\u001b[0;32m   2701\u001b[0m \u001b[39m# standardization code.\u001b[39;00m\n\u001b[0;32m   2702\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training_utils_v1.py:714\u001b[0m, in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    712\u001b[0m shape \u001b[39m=\u001b[39m shapes[i]\n\u001b[0;32m    713\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data_shape) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(shape):\n\u001b[1;32m--> 714\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    715\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError when checking \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    716\u001b[0m         \u001b[39m+\u001b[39m exception_prefix\n\u001b[0;32m    717\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m: expected \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    718\u001b[0m         \u001b[39m+\u001b[39m names[i]\n\u001b[0;32m    719\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m to have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    720\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(shape))\n\u001b[0;32m    721\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m dimensions, but got array \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith shape \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(data_shape)\n\u001b[0;32m    723\u001b[0m     )\n\u001b[0;32m    724\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m check_batch_axis:\n\u001b[0;32m    725\u001b[0m     data_shape \u001b[39m=\u001b[39m data_shape[\u001b[39m1\u001b[39m:]\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_5_input to have 4 dimensions, but got array with shape (1, 7)"
     ]
    }
   ],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam())\n",
    "dqn.fit(env, nb_steps=100, visualize=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4e0c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env.reset =env.reset_uavs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
